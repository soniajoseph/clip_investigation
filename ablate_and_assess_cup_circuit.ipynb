{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess cup circuit\n",
    "\n",
    "The purpose of this notebook is to assess the cup circuit based on output accuracy.\n",
    "\n",
    "If we have isolated the Cup Circuit and set it to the identity matrix, then TinyCLIP will be unable to classify cups but should retain performance on everything else.\n",
    "\n",
    "The isolated Cup Circuit should classify cups but have poor performance on non-cups.\n",
    "\n",
    "*To do: ROC curves.* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TinyCLIP accuracy given a model\n",
    "\n",
    "Function to get accuracy on cup and non-cup classification. Get accuracy of a vanilla net. Do top 5 classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load imagenet\n",
    "\n",
    "\n",
    "# Path to your imagenet_class.json file\n",
    "json_file_path = '/home/mila/s/sonia.joseph/ViT-Planetarium/my_draft/test_nbs/imagenet_class_index.json'\n",
    "imagenet_path = '/network/datasets/imagenet.var/imagenet_torchvision/val/'\n",
    "\n",
    "# Load the JSON file into a Python dictionary\n",
    "with open(json_file_path, 'r') as file:\n",
    "    num_to_word_dict = json.load(file)\n",
    "\n",
    "# Create a reverse dictionary for word to number mapping\n",
    "word_to_num_dict = {}\n",
    "for num, words in num_to_word_dict.items():\n",
    "    for word in words:  # Assuming each entry in num_to_word_dict is a list of words\n",
    "        word_to_num_dict[word] = num\n",
    "\n",
    "# Function to get the class name from a label\n",
    "def get_class_name(label):\n",
    "    # Assuming the label maps to a list of class names\n",
    "    return num_to_word_dict.get(str(label), [\"Unknown label\"])[1]\n",
    "\n",
    "# Function to get the label from a class name\n",
    "def get_label(class_name):\n",
    "    return word_to_num_dict.get(class_name, \"Unknown class name\")\n",
    "\n",
    "# Get class names\n",
    "imagenet_class_nums = np.arange(0, 1000, 1)\n",
    "imagenet_class_names = [\"{}\".format(get_class_name(i)) for i in imagenet_class_nums]\n",
    "\n",
    "# Set the seed. You don't need indices if data is loaded in same order every time.\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "# Create 500 random samples from the ImageNet dataset\n",
    "# num_samples = 500\n",
    "# random_indices = np.random.choice(len(imagenet_data), num_samples, replace=False)\n",
    "\n",
    "# Save the order of these indices\n",
    "# np.save('imagenet_sample_indices.npy', random_indices)\n",
    "\n",
    "# Function to load images based on saved order\n",
    "def load_images_in_order(indices_path, imagenet_dataset):\n",
    "    indices = np.load(indices_path)\n",
    "    subset_dataset = Subset(imagenet_dataset, indices)\n",
    "    data_loader = DataLoader(subset_dataset, batch_size=1)\n",
    "    return data_loader\n",
    "\n",
    "imagenet_data = datasets.ImageFolder(imagenet_path, transform=data_transforms)\n",
    "\n",
    "# Example of how to use the function\n",
    "data_loader = load_images_in_order('imagenet_sample_indices.npy', imagenet_data)\n",
    "\n",
    "\n",
    "# Load the ImageNet dataset\n",
    "batch_size = 1\n",
    "imagenet_data = datasets.ImageFolder(imagenet_path, transform=data_transforms)\n",
    "data_loader = load_images_in_order('imagenet_sample_indices.npy', imagenet_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"wkcn/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M\")\n",
    "processor = CLIPProcessor.from_pretrained(\"wkcn/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M\", do_rescale=False) # Make sure the do_rescale is false for pytorch datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cup_classes = [\n",
    "    \"measuring_cup\",\n",
    "    \"coffee_mug\",\n",
    "    \"water_jug\",\n",
    "    \"whiskey_jug\",\n",
    "    \"beer_bottle\",\n",
    "    \"pill_bottle\",\n",
    "    \"pop_bottle\",\n",
    "    \"water_bottle\",\n",
    "    \"wine_bottle\",\n",
    "    \"washbasin\",\n",
    "    \"beaker\",\n",
    "    \"vase\",\n",
    "    \"cauldron\",\n",
    "    \"coffeepot\",\n",
    "    \"teapot\",\n",
    "    \"barrel\",\n",
    "    \"bathtub\",\n",
    "    \"bucket\",\n",
    "    \"ladle\",\n",
    "    \"mortar\",\n",
    "    \"pitcher\",\n",
    "    \"tub\",\n",
    "    \"mixing_bowl\",\n",
    "    \"soup_bowl\",\n",
    "    \"Petri dish\",\n",
    "    \"milk_can\",\n",
    "    \"beer_glass\",\n",
    "    \"goblet\",\n",
    "    \"cocktail_shaker\",\n",
    "    \"saltshaker\",\n",
    "    \"pot\",\n",
    "    \"thimble\",\n",
    "    \"hot_pot\",\n",
    "    \"trifle\",\n",
    "    \"consomme\",\n",
    "    \"espresso\",\n",
    "    \"red_wine\",\n",
    "    \"cup\",\n",
    "    \"eggnog\"\n",
    "]\n",
    "\n",
    "dog_classes = [\n",
    "    \"chihuahua\",\n",
    "    \"japanese_spaniel\",\n",
    "    \"maltese_dog\",\n",
    "    \"pekinese\",\n",
    "    \"shih-tzu\",\n",
    "    \"blenheim_spaniel\",\n",
    "    \"papillon\",\n",
    "    \"toy_terrier\",\n",
    "    \"rhodesian_ridgeback\",\n",
    "    \"afghan_hound\",\n",
    "    \"basset\",\n",
    "    \"beagle\",\n",
    "    \"bloodhound\",\n",
    "    \"bluetick\",\n",
    "    \"black-and-tan_coonhound\",\n",
    "    \"walker_hound\",\n",
    "    \"english_foxhound\",\n",
    "    \"redbone\",\n",
    "    \"borzoi\",\n",
    "    \"irish_wolfhound\",\n",
    "    \"italian_greyhound\",\n",
    "    \"whippet\",\n",
    "    \"ibizan_hound\",\n",
    "    \"norwegian_elkhound\",\n",
    "    \"otterhound\",\n",
    "    \"saluki\",\n",
    "    \"scottish_deerhound\",\n",
    "    \"weimaraner\",\n",
    "    \"staffordshire_bullterrier\",\n",
    "    \"american_staffordshire_terrier\",\n",
    "    \"bedlington_terrier\",\n",
    "    \"border_terrier\",\n",
    "    \"kerry_blue_terrier\",\n",
    "    \"irish_terrier\",\n",
    "    \"norfolk_terrier\",\n",
    "    \"norwich_terrier\",\n",
    "    \"yorkshire_terrier\",\n",
    "    \"wire-haired_fox_terrier\",\n",
    "    \"lakeland_terrier\",\n",
    "    \"sealyham_terrier\",\n",
    "    \"airedale\",\n",
    "    \"cairn\",\n",
    "    \"australian_terrier\",\n",
    "    \"dandie_dinmont\",\n",
    "    \"boston_bull\",\n",
    "    \"miniature_schnauzer\",\n",
    "    \"giant_schnauzer\",\n",
    "    \"standard_schnauzer\",\n",
    "    \"scotch_terrier\",\n",
    "    \"tibetan_terrier\",\n",
    "    \"silky_terrier\",\n",
    "    \"soft-coated_wheaten_terrier\",\n",
    "    \"west_highland_white_terrier\",\n",
    "    \"lhasa\",\n",
    "    \"flat-coated_retriever\",\n",
    "    \"curly-coated_retriever\",\n",
    "    \"golden_retriever\",\n",
    "    \"labrador_retriever\",\n",
    "    \"chesapeake_bay_retriever\",\n",
    "    \"german_short-haired_pointer\",\n",
    "    \"vizsla\",\n",
    "    \"english_setter\",\n",
    "    \"irish_setter\",\n",
    "    \"gordon_setter\",\n",
    "    \"brittany_spaniel\",\n",
    "    \"clumber\",\n",
    "    \"english_springer\",\n",
    "    \"welsh_springer_spaniel\",\n",
    "    \"cocker_spaniel\",\n",
    "    \"sussex_spaniel\",\n",
    "    \"irish_water_spaniel\",\n",
    "    \"kuvasz\",\n",
    "    \"schipperke\",\n",
    "    \"groenendael\",\n",
    "    \"malinois\",\n",
    "    \"briard\",\n",
    "    \"kelpie\",\n",
    "    \"komondor\",\n",
    "    \"old_english_sheepdog\",\n",
    "    \"shetland_sheepdog\",\n",
    "    \"collie\",\n",
    "    \"border_collie\",\n",
    "    \"bouvier_des_flandres\",\n",
    "    \"rottweiler\",\n",
    "    \"german_shepherd\",\n",
    "    \"doberman\",\n",
    "    \"miniature_pinscher\",\n",
    "    \"greater_swiss_mountain_dog\",\n",
    "    \"bernese_mountain_dog\",\n",
    "    \"appenzeller\",\n",
    "    \"entlebucher\",\n",
    "    \"boxer\",\n",
    "    \"bull_mastiff\",\n",
    "    \"tibetan_mastiff\",\n",
    "    \"french_bulldog\",\n",
    "    \"great_dane\",\n",
    "    \"saint_bernard\",\n",
    "    \"eskimo_dog\",\n",
    "    \"malamute\",\n",
    "    \"siberian_husky\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache average dog activations\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "num_layers = 10\n",
    "layer_types = ['fc1', 'fc2']\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "all_layers_avg_dog_activation = pd.DataFrame()\n",
    "\n",
    "for layer_num in range(num_layers):\n",
    "    for layer_type in layer_types:\n",
    "        loaded = load_cached_act(layer_num, layer_type)\n",
    "        avg_dog_activation = loaded[loaded['class_name'].isin(dog_classes)].groupby('neuron_idx')['activation_value'].mean().reset_index()\n",
    "        avg_dog_activation['layer_num'] = layer_num\n",
    "        avg_dog_activation['layer_type'] = layer_type\n",
    "        all_layers_avg_dog_activation = pd.concat([all_layers_avg_dog_activation, avg_dog_activation])\n",
    "\n",
    "# Reset index of the final DataFrame\n",
    "all_layers_avg_dog_activation.reset_index(drop=True, inplace=True)\n",
    "\n",
    "save_path = '/network/scratch/s/sonia.joseph/clip_mechinterp/tinyclip/mini_dataset/'\n",
    "file_name_to_save = 'avg_dog_activations.parquet'\n",
    "all_layers_avg_dog_activation.to_parquet(os.path.join(save_path, file_name_to_save))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neuron_idx</th>\n",
       "      <th>activation_value</th>\n",
       "      <th>layer_num</th>\n",
       "      <th>layer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.155099</td>\n",
       "      <td>0</td>\n",
       "      <td>fc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.504439</td>\n",
       "      <td>0</td>\n",
       "      <td>fc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>0</td>\n",
       "      <td>fc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.041977</td>\n",
       "      <td>0</td>\n",
       "      <td>fc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.389680</td>\n",
       "      <td>0</td>\n",
       "      <td>fc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12795</th>\n",
       "      <td>251</td>\n",
       "      <td>-0.006281</td>\n",
       "      <td>9</td>\n",
       "      <td>fc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12796</th>\n",
       "      <td>252</td>\n",
       "      <td>-0.028464</td>\n",
       "      <td>9</td>\n",
       "      <td>fc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12797</th>\n",
       "      <td>253</td>\n",
       "      <td>-0.075678</td>\n",
       "      <td>9</td>\n",
       "      <td>fc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12798</th>\n",
       "      <td>254</td>\n",
       "      <td>0.078801</td>\n",
       "      <td>9</td>\n",
       "      <td>fc2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12799</th>\n",
       "      <td>255</td>\n",
       "      <td>-0.057906</td>\n",
       "      <td>9</td>\n",
       "      <td>fc2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       neuron_idx  activation_value  layer_num layer_type\n",
       "0               0         -1.155099          0        fc1\n",
       "1               1         -1.504439          0        fc1\n",
       "2               2         -0.001310          0        fc1\n",
       "3               3          0.041977          0        fc1\n",
       "4               4         -1.389680          0        fc1\n",
       "...           ...               ...        ...        ...\n",
       "12795         251         -0.006281          9        fc2\n",
       "12796         252         -0.028464          9        fc2\n",
       "12797         253         -0.075678          9        fc2\n",
       "12798         254          0.078801          9        fc2\n",
       "12799         255         -0.057906          9        fc2\n",
       "\n",
       "[12800 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_layers_avg_dog_activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_resampling_activation(df, neuron_idx, layer_num, layer_type):\n",
    "    \"\"\"\n",
    "    Retrieve the activation value for a specific neuron index, layer number, and layer type.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The DataFrame containing the neuron activations.\n",
    "    neuron_idx (int): The index of the neuron.\n",
    "    layer_num (int): The layer number.\n",
    "    layer_type (str): The type of the layer (e.g., 'fc1', 'fc2').\n",
    "\n",
    "    Returns:\n",
    "    float: The activation value, or None if not found.\n",
    "    \"\"\"\n",
    "    result = df[(df['neuron_idx'] == neuron_idx) & \n",
    "                (df['layer_num'] == layer_num) & \n",
    "                (df['layer_type'] == layer_type)]\n",
    "\n",
    "    if not result.empty:\n",
    "        return result['activation_value'].iloc[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "act = get_resampling_activation(all_layers_avg_dog_activation, 0, 0, 'fc1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/network/scratch/s/sonia.joseph/clip_mechinterp/tinyclip/mini_dataset/'\n",
    "file_name_to_save = 'avg_dog_activations.parquet'\n",
    "\n",
    "\n",
    "# Load the average dog activations\n",
    "avg_dog_activations = pd.read_parquet(os.path.join(save_path, file_name_to_save))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, roc_auc, title):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def is_cup_class(class_name):\n",
    "    return class_name in cup_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431793d335454233baf8c8d9ca03c477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_873/1544355327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Run for cup classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mfpr_cup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_cup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_cup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_cup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_roc_and_accuracy_for_top5_subsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcup_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Cup Class - Top-5 ROC AUC: {roc_auc_cup:.2f}, Top-5 Accuracy: {accuracy_cup:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mplot_roc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr_cup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr_cup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_cup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ROC for Top-5 Predictions in Cup Classes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_873/1544355327.py\u001b[0m in \u001b[0;36mcalculate_roc_and_accuracy_for_top5_subsets\u001b[0;34m(data_loader, model, processor, is_cup_class)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# Process the images and get model outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimagenet_class_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_per_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, pixel_values, attention_mask, position_ids, return_loss, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1137\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1138\u001b[0m         )\n\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         )\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs_embeds, attention_mask, causal_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    656\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                     \u001b[0mcausal_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 )\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/transformers/models/clip/modeling_clip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ViT-Planetarium/env/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def calculate_roc_and_accuracy_for_top5_subsets(data_loader, model, processor, is_cup_class):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_scores = []\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data_loader):\n",
    "            # Process the images and get model outputs\n",
    "            inputs = processor(text=imagenet_class_names, images=images, return_tensors=\"pt\", padding=True)\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits_per_image\n",
    "\n",
    "            # Check if true label is in top 5 predictions\n",
    "            top5_preds = logits.topk(5).indices.squeeze(0).tolist()\n",
    "            is_top5 = labels.item() in top5_preds\n",
    "\n",
    "            actual_class_name = get_class_name(labels.item())\n",
    "            if is_cup_class(actual_class_name):\n",
    "                y_true.append(1)  # Label 1 for cup class instances\n",
    "                y_scores.append(is_top5)\n",
    "                correct_predictions += is_top5\n",
    "                total_predictions += 1\n",
    "\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "\n",
    "    return fpr, tpr, roc_auc, accuracy\n",
    "\n",
    "# Run for cup classes\n",
    "fpr_cup, tpr_cup, roc_auc_cup, accuracy_cup = calculate_roc_and_accuracy_for_top5_subsets(data_loader, model, processor, lambda x: x in cup_classes)\n",
    "print(f\"Cup Class - Top-5 ROC AUC: {roc_auc_cup:.2f}, Top-5 Accuracy: {accuracy_cup:.2f}\")\n",
    "plot_roc_curve(fpr_cup, tpr_cup, roc_auc_cup, 'ROC for Top-5 Predictions in Cup Classes')\n",
    "\n",
    "# Run for non-cup classes\n",
    "fpr_non_cup, tpr_non_cup, roc_auc_non_cup, accuracy_non_cup = calculate_roc_and_accuracy_for_top5_subsets(data_loader, model, processor, lambda x: x not in cup_classes)\n",
    "print(f\"Non-Cup Class - Top-5 ROC AUC: {roc_auc_non_cup:.2f}, Top-5 Accuracy: {accuracy_non_cup:.2f}\")\n",
    "plot_roc_curve(fpr_non_cup, tpr_non_cup, roc_auc_non_cup, 'ROC for Top-5 Predictions in Non-Cup Classes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write function to ablate circuit given a list of MLP neurons\n",
    "\n",
    "Ablate list, then get accuracy on cups + non-cups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df of logit differences for all layers (fc1 + f2)\n",
    "def load_logit_diff_dict(layer_num, neuron_type, layer_type=None):\n",
    "    load_dir = f'/network/scratch/s/sonia.joseph/clip_mechinterp/tinyclip/logit_differences/cup_logits'\n",
    "\n",
    "    if not layer_type:\n",
    "        file_name = f'neuron_dict_{layer_num}_{neuron_type}.npy'\n",
    "    else:\n",
    "        file_name = f'neuron_dict_{layer_num}_{neuron_type}_{layer_type}.npy'\n",
    "    \n",
    "\n",
    "    neuron_dict = np.load(f'{load_dir}/{file_name}', allow_pickle=True).item()\n",
    "\n",
    "    # Get average of every entry in neuron_dict\n",
    "    # avgs = [np.mean(neuron_dict[key]) for key in neuron_dict.keys()]\n",
    "    return neuron_dict\n",
    "\n",
    "# Create df of dog ablation values\n",
    "def filter_neurons_by_threshold(neuron_dict, threshold):\n",
    "    filtered_dict = {neuron: np.mean(values) for neuron, values in neuron_dict.items() if np.mean(values) < threshold}\n",
    "    return filtered_dict\n",
    "\n",
    "# num_layers = 10  # Replace with the actual number of layers\n",
    "# neuron_type = 'cups'  # or any other neuron type\n",
    "# layer_type = None  # or specify the layer type if needed\n",
    "# threshold = 0.5  # Set your threshold value\n",
    "\n",
    "# # Example for layer_num = 1 (you can loop over layers if needed)\n",
    "# layer_num = 1\n",
    "# neuron_dict = load_logit_diff_dict(layer_num, neuron_type, layer_type)\n",
    "\n",
    "# # Calculating average logit values and filtering\n",
    "# filtered_neurons = filter_neurons_by_threshold(neuron_dict, threshold)\n",
    "\n",
    "\n",
    "# # Assuming there are N layers\n",
    "# num_layers = 10  # Replace 12 with the actual number of layers\n",
    "# neuron_type = 'cups'  # or any other neuron type you're interested in\n",
    "# layer_type = None  # or specify the layer type if needed\n",
    "\n",
    "# # Initialize a list to store averages for each layer\n",
    "\n",
    "# # Initialize lists to store averages for each layer\n",
    "# avgs_fc1 = []\n",
    "# avgs_fc2 = []\n",
    "\n",
    "# for layer_num in range(0, num_layers):\n",
    "#     avgs_fc1.append(load_logit_diff_dict(layer_num, neuron_type, None))\n",
    "#     # avgs_fc2.append(load_logit_diff_dict(layer_num, neuron_type, 'fc2'))\n",
    "\n",
    "# # Now, create a DataFrame\n",
    "# df = pd.DataFrame({\n",
    "#     'Layer_Num': range(0, num_layers), \n",
    "#     'Average_Logit_Differences_FC1': avgs_fc1,\n",
    "#     # 'Average_Logit_Differences_FC2': avgs_fc2\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logit_diff_dict(layer_num, neuron_type, layer_type):\n",
    "    load_dir = '/network/scratch/s/sonia.joseph/clip_mechinterp/tinyclip/logit_differences/cup_logits'\n",
    "    if layer_type is None:\n",
    "        file_name = f'neuron_dict_{layer_num}_{neuron_type}.npy'\n",
    "    else:\n",
    "        file_name = f'neuron_dict_{layer_num}_{neuron_type}_{layer_type}.npy'\n",
    "        \n",
    "    neuron_dict = np.load(f'{load_dir}/{file_name}', allow_pickle=True).item()\n",
    "    return neuron_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def calculate_average_logit_values(num_layers, neuron_type, layer_types):\n",
    "    all_layers_avg_logits = {}\n",
    "    for layer_num in range(num_layers):\n",
    "        all_layers_avg_logits[layer_num] = {}\n",
    "        for layer_type in layer_types:\n",
    "            neuron_dict = load_logit_diff_dict(layer_num, neuron_type, layer_type)\n",
    "            avg_logits = {neuron: np.mean(values) for neuron, values in neuron_dict.items()}\n",
    "            if layer_type == None:\n",
    "                layer_type = 'fc1'\n",
    "            all_layers_avg_logits[layer_num][layer_type] = avg_logits\n",
    "\n",
    "    return all_layers_avg_logits\n",
    "\n",
    "def filter_dict_by_threshold(nested_dict, threshold, below_threshold=True):\n",
    "    filtered_dict = {}\n",
    "    for layer, layer_data in nested_dict.items():\n",
    "        filtered_dict[layer] = {}\n",
    "        for module, neuron_data in layer_data.items():\n",
    "            if below_threshold:\n",
    "                filtered_dict[layer][module] = {neuron: avg for neuron, avg in neuron_data.items() if avg < threshold}\n",
    "            else:\n",
    "                filtered_dict[layer][module] = {neuron: avg for neuron, avg in neuron_data.items() if avg > threshold}\n",
    "    return filtered_dict\n",
    "\n",
    "num_layers = 10\n",
    "neuron_type = 'cups'\n",
    "layer_types = [None, 'fc2']\n",
    "threshold = -50 # Define your threshold\n",
    "\n",
    "# Calculate average logit values for each neuron in each module and layer\n",
    "avg_logit_values = calculate_average_logit_values(num_layers, neuron_type, layer_types)\n",
    "\n",
    "# Filter the dictionary based on the threshold\n",
    "filtered_logit_values = filter_dict_by_threshold(avg_logit_values, threshold, below_threshold=True)\n",
    "\n",
    "# Now, filtered_logit_values contains the data structured by layer and module, filtered by the threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'fc1': {}, 'fc2': {}},\n",
       " 1: {'fc1': {}, 'fc2': {}},\n",
       " 2: {'fc1': {}, 'fc2': {}},\n",
       " 3: {'fc1': {}, 'fc2': {}},\n",
       " 4: {'fc1': {}, 'fc2': {}},\n",
       " 5: {'fc1': {161: -95.1619978249073, 847: -76.28898281604052},\n",
       "  'fc2': {161: -60.599219128489494}},\n",
       " 6: {'fc1': {333: -58.20064886473119}, 'fc2': {}},\n",
       " 7: {'fc1': {128: -149.6555608510971,\n",
       "   150: -107.33996614813805,\n",
       "   734: -51.00202553905547},\n",
       "  'fc2': {128: -136.68424516916275, 150: -88.7842807173729}},\n",
       " 8: {'fc1': {90: -51.954936385154724, 461: -102.86492738872766}, 'fc2': {}},\n",
       " 9: {'fc1': {682: -66.1489588022232, 887: -53.825907818973064}, 'fc2': {}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_logit_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get average of dog neurons from cached activations\n",
    "# def load_cached_act(layer_num, layer_type, save_path = '/network/scratch/s/sonia.joseph/clip_mechinterp/tinyclip/mini_dataset/'):\n",
    "#     \"\"\"\n",
    "#     Load cached activations and calculate per-neuron z-scores.\n",
    "#     \"\"\"\n",
    "\n",
    "#     file_name = f'mlp_{layer_type}_{layer_num}.npz'\n",
    "#     loaded = pd.read_parquet(os.path.join(save_path, file_name))\n",
    "\n",
    "#     return loaded\n",
    "    \n",
    "    \n",
    "# layer_num = 7\n",
    "# layer_type = 'fc1'\n",
    "# loaded = load_cached_act(layer_num, layer_type)\n",
    "# avg_dog_activation = loaded[loaded['class_name'].isin(dog_classes)].groupby('neuron_idx')['activation_value'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_metric(logits, cup_indices):\n",
    "    # Convert cup_indices to a tensor if it's a list\n",
    "    cup_indices_tensor = torch.tensor(cup_indices, dtype=torch.long)\n",
    "\n",
    "    # Create a boolean mask for all logits: False for cup indices, True for others\n",
    "\n",
    "    mask = torch.ones(logits.shape[1], dtype=torch.bool)  # All True initially\n",
    "    mask[cup_indices_tensor] = False  # Set False for cup indices\n",
    "\n",
    "    # Extract cup logits\n",
    "    cup_logit = logits[:, cup_indices_tensor]\n",
    "\n",
    "    # Extract non-cup logits using the inverted mask\n",
    "    non_cup_logit = logits[:, mask]\n",
    "\n",
    "    diff = logsumexp(cup_logit, axis=1).mean() - logsumexp(non_cup_logit, axis=1).mean()\n",
    "\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter logit difference df by threshold\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "def create_custom_hook(neuron_idx, new_value):\n",
    "    # This is the actual hook function\n",
    "    def custom_forward_hook(module, input, output):\n",
    "        # Modify the output for the specified neuron\n",
    "        output[:, :, neuron_idx] = new_value\n",
    "        return output\n",
    "    return custom_forward_hook\n",
    "\n",
    "\n",
    "def transform_images(img_directory, image_path):\n",
    "    image = Image.open(os.path.join(img_directory, image_path)).convert('RGB')\n",
    "\n",
    "    # Define the transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to the input size expected by the CLIP model\n",
    "        transforms.ToTensor(),          # Convert to PyTorch Tensor\n",
    "        # transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])  # Normalize (specific to CLIP)\n",
    "    ])\n",
    "\n",
    "    # Apply the transformation\n",
    "    image_tensor = transform(image)\n",
    "\n",
    "    # Add a batch dimension\n",
    "    image_tensor = image_tensor.unsqueeze(0) \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "def ablate_subgraph(filtered_logit_values, model):\n",
    "    ablated_model = copy.deepcopy(model)\n",
    "    hook_handles = []\n",
    "    for layer_num, layer_data in filtered_logit_values.items():\n",
    "        for layer_type, neurons in layer_data.items():\n",
    "            for neuron_idx, new_value in neurons.items():\n",
    "                # print(f'Layer {layer_num}, {layer_type}, Neuron {neuron_idx}')\n",
    "                new_value = get_resampling_activation(avg_dog_activations, neuron_idx, layer_num, layer_type)\n",
    "                custom_hook_function = create_custom_hook(neuron_idx, new_value)\n",
    "                module = getattr(ablated_model.vision_model.encoder.layers[layer_num].mlp, layer_type)\n",
    "                hook_handle = module.register_forward_hook(custom_hook_function)\n",
    "                hook_handles.append(hook_handle)\n",
    "\n",
    "\n",
    "    cup_dir = '/home/mila/s/sonia.joseph/CLIP_mechinterp/sample_images/cup_images'\n",
    "    new_cup_images = ['beer.png','many_cups.png','blue_cup.png','two_cups.png','tub.png']\n",
    "    new_cup_images = [transform_images(cup_dir, image_path) for image_path in new_cup_images]\n",
    "\n",
    "    total_vanilla_diff = []\n",
    "    total_abl_diff = []\n",
    "    \n",
    "    for image in new_cup_images:\n",
    "        inputs = processor(text=imagenet_class_names, images=image, return_tensors=\"pt\", padding=True)\n",
    "        ablated_outputs = ablated_model(**inputs)\n",
    "        logits_per_image = ablated_outputs.logits_per_image\n",
    "        ablated_logits = logits_per_image.detach().numpy()\n",
    "\n",
    "        # Vanilla logits\n",
    "        vanilla_outputs = model(**inputs)\n",
    "        vanilla_logits_per_image = vanilla_outputs.logits_per_image\n",
    "        vanilla_logits = vanilla_logits_per_image.detach().numpy()\n",
    "\n",
    "        vanilla_diff = logit_metric(vanilla_logits, cup_indices)\n",
    "        abl_diff = logit_metric(ablated_logits, cup_indices)\n",
    "\n",
    "        # print('vanilla diff', vanilla_diff)\n",
    "        # print('abl diff', abl_diff)\n",
    "\n",
    "        total_vanilla_diff.append(vanilla_diff)\n",
    "        total_abl_diff.append(abl_diff)\n",
    "\n",
    "    return np.mean(total_vanilla_diff), np.mean(total_abl_diff), ablated_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_change(old_value, new_value):\n",
    "    return (new_value - old_value) / np.abs(old_value) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "cup_indices = [imagenet_class_names.index(cup_name) for cup_name in cup_classes if cup_name in imagenet_class_names]\n",
    "\n",
    "# vanilla_diff = logit_metric(vanilla_logits, cup_indices)\n",
    "# abl_diff = logit_metric(ablated_logits, cup_indices)\n",
    "\n",
    "# pc = percent_change(vanilla_diff, abl_diff)\n",
    "\n",
    "# print(\"percent change\", pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get accuracy\n",
    "\n",
    "def get_accuracy(data_loader, model, processor):\n",
    "    fpr_cup, tpr_cup, roc_auc_cup, accuracy_cup = calculate_roc_and_accuracy_for_top5_subsets(data_loader, ablated_model, processor, lambda x: x in cup_classes)\n",
    "    print(f\"Cup Class - Top-5 ROC AUC: {roc_auc_cup:.2f}, Top-5 Accuracy: {accuracy_cup:.2f}\")\n",
    "    plot_roc_curve(fpr_cup, tpr_cup, roc_auc_cup, 'ROC for Top-5 Predictions in Cup Classes')\n",
    "\n",
    "    # Run for non-cup classes\n",
    "    fpr_non_cup, tpr_non_cup, roc_auc_non_cup, accuracy_non_cup = calculate_roc_and_accuracy_for_top5_subsets(data_loader, ablated_model, processor, lambda x: x not in cup_classes)\n",
    "    print(f\"Non-Cup Class - Top-5 ROC AUC: {roc_auc_non_cup:.2f}, Top-5 Accuracy: {accuracy_non_cup:.2f}\")\n",
    "    plot_roc_curve(fpr_non_cup, tpr_non_cup, roc_auc_non_cup, 'ROC for Top-5 Predictions in Non-Cup Classes')\n",
    "\n",
    "    return accuracy_cup, accuracy_non_cup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2adb458f3345d58c156d803ea079d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold -100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66a1ff3c4074bff8dadf3178fdcee09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cup Class - Top-5 ROC AUC: nan, Top-5 Accuracy: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/s/sonia.joseph/ViT-Planetarium/env/lib/python3.7/site-packages/sklearn/metrics/_ranking.py:992: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e116e86b87404f0ca8be0f439496de79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try with different thresholds\n",
    "thresholds = [-100, -50, -25, -10, -5, 0, 5, 10, 25, 50]\n",
    "\n",
    "total_percents = []\n",
    "total_acc_cup = []\n",
    "total_acc_non_cup = []\n",
    "\n",
    "for t in tqdm(thresholds):\n",
    "    print('threshold', t)\n",
    "    if t <= 0:\n",
    "        filtered_logit_values = filter_dict_by_threshold(avg_logit_values, t, below_threshold=True)\n",
    "    else:\n",
    "        filtered_logit_values = filter_dict_by_threshold(avg_logit_values, t, below_threshold=False)\n",
    "    vanilla_diff, ablated_diff, ablated_model = ablate_subgraph(filtered_logit_values, model)\n",
    "    pc = percent_change(vanilla_diff, ablated_diff)\n",
    "    total_percents.append(pc)\n",
    "    acc_cup, accuracy_non_cup = get_accuracy(data_loader, ablated_model, processor)\n",
    "    print('accuracy cup', acc_cup)\n",
    "    print('accuracy non cup', accuracy_non_cup)\n",
    "\n",
    "    total_acc_cup.append(acc_cup)\n",
    "    total_acc_non_cup.append(accuracy_non_cup)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(thresholds, total_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write function to isolate a subgraph given a list of neurons\n",
    "\n",
    "Isolate subgraph by using resampling activations on non-subgraph neurons. Then run cup and non-cup classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
